---
title: Reasoning Tools
description: Give any model explicit tools for structured thinking—transforming regular models into careful problem-solvers through deliberate reasoning steps.
---

**The problem:** Reasoning Agents force systematic thinking on every request. Reasoning Models require specialized models. What if you want reasoning only when needed?

**The solution:** Reasoning Tools give your agent explicit `think()` and `analyze()` tools—and let the agent decide when to use them. The agent chooses when to reason, when to act, and when it has enough information to respond.

This approach was first popularized by Anthropic in their ["Extended Thinking" blog post](https://www.anthropic.com/engineering/claude-think-tool), though many AI engineers (including our team) were using similar patterns long before.

## Why Reasoning Tools?

Reasoning Tools give you the **best of both worlds**:

1. **Works with any model** - Even models without native reasoning capabilities
2. **Explicit control** - The agent decides when to think vs. when to act
3. **Full transparency** - You see exactly what the agent is thinking
4. **Flexible workflow** - The agent can interleave thinking with tool calls
5. **Natural reasoning** - Feels more like human problem-solving (think, act, analyze, repeat)

**The key difference:** With Reasoning Agents, the reasoning happens automatically in a structured loop. With Reasoning Tools, the agent explicitly chooses when to use the `think()` and `analyze()` tools—giving you more control and visibility.

## How It Works

The `ReasoningTools` class provides two primary tools:

### 1. The `think()` Tool - Your Mental Scratchpad

The `think()` tool acts as a scratchpad where the agent works through problems step-by-step before taking action.

**Purpose:**

- Break down complex problems into logical steps
- Plan actions before executing them
- Record assumptions and reasoning
- Structure internal thought process

**Parameters:**

- `title` (str) - A concise title for this thinking step
- `thought` (str) - The detailed reasoning for this step
- `action` (str, optional) - What the agent plans to do based on this thought
- `confidence` (float) - Confidence level from 0.0 to 1.0 (default: 0.8)

**Returns:** A formatted list of all previous thoughts plus the new thought, creating a running record of the agent's reasoning.

**Example:**

```python
think(
    title="Understand User Intent",
    thought="The user is asking about semiconductor market performance. I need to gather data on NVDA, AMD, INTC, and TSM stock prices, market cap, and recent news.",
    action="Search for current stock data for each company",
    confidence=0.95
)
```

### 2. The `analyze()` Tool - Result Evaluation

The `analyze()` tool evaluates results from previous actions or thoughts and determines next steps.

**Purpose:**

- Evaluate whether results meet expectations
- Determine if more information is needed
- Decide when to conclude or continue
- Validate findings

**Parameters:**

- `title` (str) - A concise title for this analysis step
- `result` (str) - The outcome of the previous action
- `analysis` (str) - Your evaluation of the results
- `next_action` (str) - What to do next: `"continue"`, `"validate"`, or `"final_answer"` (default: `"continue"`)
- `confidence` (float) - Confidence level from 0.0 to 1.0 (default: 0.8)

**Returns:** A formatted list of all previous reasoning steps plus the new analysis.

**Example:**

```python
analyze(
    title="Evaluate Stock Data",
    result="Found Q4 data: NVDA +45%, AMD +12%, INTC -8%, TSM +22%",
    analysis="I have growth data for all four companies. NVDA shows exceptional growth, likely driven by AI chip demand. Need to search for news to understand the drivers.",
    next_action="continue",
    confidence=0.9
)
```

### The Reasoning Workflow

Reasoning Tools follow a natural **Think → Act → Analyze** cycle:

1. **Think** - Plan what to do and why
2. **Act** - Execute tool calls (search, calculate, retrieve data)
3. **Analyze** - Evaluate results and decide next steps
4. **Repeat** - Continue until reaching `final_answer`

This mirrors how humans solve complex problems: we think before acting, evaluate results, and adjust our approach based on what we learn.

## Basic Example

Here's a simple example showing the complete workflow:

```python basic_reasoning_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ReasoningTools(add_instructions=True)],  # Enable reasoning tools
    markdown=True,
)

reasoning_agent.print_response(
    "Which is bigger: 9.11 or 9.9? Explain your reasoning.",
    stream=True,
    stream_intermediate_steps=True,
)
```

**What happens:**

1. Agent calls `think()`: "Need to compare decimal values, not digit-by-digit"
2. Agent performs mental calculation
3. Agent calls `analyze()`: "9.9 = 9.90, which is greater than 9.11"
4. Agent sets `next_action="final_answer"`
5. Agent provides final response to user

## Reasoning with External Tools

The real power emerges when combining reasoning tools with external tools like search, databases, or APIs:

```python reasoning_with_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools
from agno.tools.duckduckgo import DuckDuckGoTools

reasoning_agent = Agent(
    model=Claude(id="claude-4-5-sonnet-latest"),
    tools=[
        ReasoningTools(add_instructions=True),
        DuckDuckGoTools(enable_search=True),
    ],
    instructions="Use tables to display data clearly",
    markdown=True,
)

reasoning_agent.print_response(
    """Analyze the semiconductor market performance focusing on:
    - NVIDIA (NVDA)
    - AMD (AMD)
    - Intel (INTC)
    - Taiwan Semiconductor (TSM)
    Compare their market positions, growth metrics, and future outlook.""",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

**The agent's workflow:**

1. `think()`: "I need current market data for 4 companies. I'll search for each one, then compare."
2. **Acts:** Makes parallel DuckDuckGo searches for all 4 companies
3. `analyze()`: "I have data for NVDA, AMD, INTC. TSM search returned limited results. Need more specific search."
4. **Acts:** Searches for "TSM Taiwan Semiconductor stock performance"
5. `analyze()`: "Now I have complete data. I can see NVDA leading in growth. Ready to create comparison."
6. **Acts:** Generates comparison table
7. `analyze()`: "Analysis is complete and comprehensive", `next_action="final_answer"`
8. **Final response:** Delivers formatted analysis to user

## Configuration Options

### Enable/Disable Specific Tools

You can control which reasoning tools are available:

```python
# Only thinking, no analysis
ReasoningTools(enable_think=True, enable_analyze=False)

# Only analysis, no thinking
ReasoningTools(enable_think=False, enable_analyze=True)

# Both (default)
ReasoningTools(enable_think=True, enable_analyze=True)

# Shorthand for both
ReasoningTools()
```

### Add Instructions Automatically

The `add_instructions` parameter automatically includes detailed reasoning guidelines in your agent's instructions:

```python
ReasoningTools(add_instructions=True)
```

This adds comprehensive instructions explaining:

- When to use `think()` vs `analyze()`
- The Think → Act → Analyze workflow
- How to determine `next_action` values
- Best practices for reasoning

**When to use:** Almost always! This ensures the agent understands how to use the tools effectively.

### Add Few-Shot Examples

Include example reasoning workflows to guide the agent:

```python
ReasoningTools(add_instructions=True, add_few_shot=True)
```

This adds practical examples showing:

- Simple fact retrieval with reasoning
- Multi-step information gathering
- How to use tools in parallel
- When to set `next_action` to different values

**When to use:**

- When working with less capable models
- For complex reasoning tasks
- When you want consistent reasoning patterns

### Custom Instructions

Provide your own custom instructions for specialized reasoning:

```python
custom_instructions = """
Use the think and analyze tools for rigorous scientific reasoning:
- Always think before making claims
- Cite evidence in your analysis
- Acknowledge uncertainty
- Consider alternative hypotheses
"""

ReasoningTools(
    instructions=custom_instructions,
    add_instructions=False  # Don't include default instructions
)
```

### Custom Few-Shot Examples

Provide domain-specific examples:

```python
medical_examples = """
Example: Medical Diagnosis

User: Patient has fever and cough for 3 days.

Agent thinks:
think(
    title="Gather Symptoms",
    thought="Need to collect all symptoms and their duration. Fever and cough suggest respiratory infection. Should check for other symptoms.",
    action="Ask about additional symptoms",
    confidence=0.9
)
"""

ReasoningTools(
    add_instructions=True,
    add_few_shot=True,
    few_shot_examples=medical_examples  # Your custom examples
)
```

## Advanced Example: Complex Problem-Solving

Here's a comprehensive example showing advanced reasoning patterns:

```python advanced_reasoning.py
from textwrap import dedent
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ReasoningTools(add_instructions=True, add_few_shot=True)],
    instructions=dedent("""
        You are an expert problem-solving assistant with strong analytical skills.

        Your approach to problems:
        1. Break down complex questions into component parts
        2. Clearly state your assumptions
        3. Develop a structured reasoning path
        4. Consider multiple perspectives
        5. Evaluate evidence and counter-arguments
        6. Draw well-justified conclusions

        For quantitative problems:
        - Show your calculations
        - Explain the significance of numbers
        - Consider confidence intervals when appropriate

        For qualitative reasoning:
        - Assess how different factors interact
        - Consider psychological and social dynamics
        - Evaluate practical constraints
    """),
    stream_intermediate_steps=True,
    markdown=True,
)

# Logic puzzle
reasoning_agent.print_response(
    "Solve this logic puzzle: A man has to take a fox, a chicken, and a sack of grain across a river. "
    "The boat is only big enough for the man and one item. If left unattended together, the fox will "
    "eat the chicken, and the chicken will eat the grain. How can the man get everything across safely?",
    stream=True,
)
```

**What you'll see:**

```
Step 1:
Title: Identify Constraints
Reasoning: The constraints are: boat capacity (1 item + man), fox eats chicken, chicken eats grain
Action: Map out all possible states
Confidence: 0.95

Step 2:
Title: Analyze Invalid States
Reasoning: Invalid states are: fox+chicken alone, chicken+grain alone. Need to avoid these.
Action: Work through sequence avoiding invalid states
Confidence: 0.9

Step 3:
Title: Solution Path
Result: Take chicken first (leaves fox+grain, which is safe). Return alone. Take fox. Return with chicken. Take grain. Return alone. Take chicken.
Analysis: This sequence never leaves fox+chicken or chicken+grain together unattended. All constraints satisfied.
Next Action: final_answer
Confidence: 0.95
```

## Monitoring Your Agent's Thinking

### Show Full Reasoning

Want to see what your agent is thinking? Display all reasoning steps to the user:

```python
agent.print_response(
    "Your question",
    show_full_reasoning=True,  # Shows think() and analyze() calls
    stream_intermediate_steps=True,  # Streams each step in real-time
)
```

### Access Reasoning Steps Programmatically

Reasoning steps are stored in the agent's session state:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ReasoningTools(add_instructions=True)],
)

response = agent.run("Solve: 2x + 5 = 13")

# Access reasoning steps
if "reasoning_steps" in agent.session_state:
    run_id = agent.session_state.get("current_run_id")
    steps = agent.session_state["reasoning_steps"].get(run_id, [])

    for step in steps:
        print(step)  # Each step is JSON
```

## Real-World Use Cases

### Financial Analysis

```python
reasoning_agent.print_response(
    "Should I invest in renewable energy stocks given current market conditions? "
    "Consider policy changes, technological trends, and market risks.",
    stream=True,
)
```

The agent will:

1. Think about factors (policy, tech, risks)
2. Search for current renewable energy policy news
3. Analyze search results
4. Search for technology trends
5. Analyze market data
6. Think through risk factors
7. Provide final recommendation with reasoning

### Legal Analysis

```python
reasoning_agent.print_response(
    "Review this contract clause for potential issues: 'The contractor shall complete "
    "all work within a reasonable timeframe as determined solely by the client.'",
    stream=True,
)
```

The agent will:

1. Think about what makes contract terms enforceable
2. Identify ambiguous terms ("reasonable timeframe")
3. Analyze the power imbalance ("determined solely by client")
4. Think through potential disputes
5. Provide analysis with recommended revisions

### Scientific Research Planning

```python
reasoning_agent.print_response(
    "Design an experiment to test whether blue light affects sleep quality. "
    "Include controls, variables, and methodology.",
    stream=True,
)
```

The agent will:

1. Think about experimental design principles
2. Define independent variables (blue light exposure)
3. Define dependent variables (sleep quality metrics)
4. Plan control groups
5. Analyze potential confounds
6. Design measurement protocol
7. Provide complete experimental design

## When to Use Reasoning Tools

**Use Reasoning Tools when:**

- You want **explicit control** over when the agent thinks vs. acts
- You need **full transparency** into the reasoning process
- You're working with **any model** (not just reasoning models)
- Your task involves **interleaving thinking with tool calls**
- You want the agent to **decide when to reason**
- You need to **see confidence levels** for each reasoning step

**Consider alternatives when:**

- You want fully **automated chain-of-thought** → use [Reasoning Agents](/concepts/reasoning/reasoning-agents)
- You have access to **native reasoning models** and want simplicity → use [Reasoning Models](/concepts/reasoning/reasoning-models)
- You need **structured prompting** without tool calls → use Reasoning Agents

## Reasoning Tools vs. Reasoning Agents

Both approaches add reasoning to any model, but they differ in control and automation:

| Aspect           | Reasoning Tools                          | Reasoning Agents                                   |
| ---------------- | ---------------------------------------- | -------------------------------------------------- |
| **Activation**   | Agent decides when to use `think()`      | Automatic on every request                         |
| **Control**      | Explicit tool calls                      | Automated loop                                     |
| **Transparency** | See every `think()` and `analyze()` call | See structured reasoning steps                     |
| **Workflow**     | Agent-driven (flexible)                  | Framework-driven (structured)                      |
| **Best for**     | Research, analysis, exploratory tasks    | Complex multi-step problems with defined structure |

**Rule of thumb:**

- Use **Reasoning Tools** when you want the agent to control its own reasoning process
- Use **Reasoning Agents** when you want guaranteed systematic thinking for every request

## Tips and Best Practices

### 1. Always Use `add_instructions=True`

The default instructions ensure the agent uses the tools correctly:

```python
# Good
ReasoningTools(add_instructions=True)

# Bad (agent won't know how to use tools effectively)
ReasoningTools(add_instructions=False)
```

### 2. Combine with Other Tools

Reasoning Tools shine when combined with external tools:

```python
from agno.tools.reasoning import ReasoningTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        ReasoningTools(add_instructions=True),
        DuckDuckGoTools(),
        YFinanceTools(),
    ],
)
```

### 3. Use `stream_intermediate_steps=True` for Debugging

See reasoning in real-time during development:

```python
agent.print_response(
    "Your question",
    stream_intermediate_steps=True,  # See each step as it happens
)
```

### 4. Guide the Agent with Custom Instructions

Add domain-specific reasoning guidance:

```python
Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions="""
        When analyzing code:
        1. Think about edge cases before suggesting changes
        2. Analyze performance implications
        3. Consider security vulnerabilities
        4. Think about maintainability
    """,
)
```

### 5. Monitor Confidence Scores

Low confidence scores signal when the agent is uncertain:

```python
# In your application
if step.confidence < 0.7:
    # Agent is uncertain - might need more information
    # Consider asking clarifying questions
```

## Developer Resources

- [Reasoning Tools Examples](/examples/concepts/reasoning/tools)
- [Reasoning Tools Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/tools)

## Next Steps

<CardGroup cols={2}>
  <Card title="Reasoning Tools Examples" icon="code" href="/examples/concepts/reasoning/tools">
    See reasoning tools solving real problems
  </Card>
  <Card title="Tools Cookbook" icon="book-open" href="https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/tools">
    Production-ready code examples and patterns
  </Card>
  <Card title="Reasoning Agents" icon="users" href="/concepts/reasoning/reasoning-agents">
    Alternative: Automated chain-of-thought
  </Card>
  <Card title="Reasoning Overview" icon="map" href="/concepts/reasoning/introduction">
    Compare all three reasoning approaches
  </Card>
</CardGroup>
