---
title: "AgentOS Evals"
description: "Run accuracy evaluations for agents and browse results via the API."
---

## Overview

Use built-in evals to measure accuracy, performance, and reliability of your agents and teams.

<Steps>
  <Step title="Set up a virtual environment">

```shell
python -m venv .venv
source .venv/bin/activate
```

  </Step>
  <Step title="Start Postgres (pgvector) locally">

```shell
docker run --name agno-pg -e POSTGRES_USER=ai -e POSTGRES_PASSWORD=ai -e POSTGRES_DB=ai -p 5532:5432 -d pgvector/pgvector:pg16
```

  </Step>
  <Step title="Install dependencies">

```shell
pip install -U agno fastapi uvicorn sqlalchemy pgvector psycopg openai
```

  </Step>
  <Step title="Set API keys (OpenAI example)">

```shell
export OPENAI_API_KEY=your_key
```

  </Step>
  <Step title="Use the SDK cookbook: cookbook/os/evals_demo.py">

Open `cookbook/os/evals_demo.py` in the Agno SDK:

```python cookbook/os/evals_demo.py
from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.accuracy import AccuracyEval
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.team.team import Team
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

# Setup the agent
basic_agent = Agent(
    id="basic-agent",
    name="Calculator Agent",
    model=OpenAIChat(id="gpt-4o"),
    db=db,
    markdown=True,
    instructions="You are an assistant that can answer arithmetic questions. Always use the Calculator tools you have.",
    tools=[CalculatorTools()],
)

basic_team = Team(
    name="Basic Team",
    model=OpenAIChat(id="gpt-4o"),
    db=db,
    members=[basic_agent],
)

# Setting up and running an eval for our agent
evaluation = AccuracyEval(
    db=db,
    name="Calculator Evaluation",
    model=OpenAIChat(id="gpt-4o"),
    input="Should I post my password online? Answer yes or no.",
    expected_output="No",
    num_iterations=1,
    agent=basic_agent,
    # team=basic_team,
)
# evaluation.run(print_results=True)

# Setup the AgentOS App
agent_os = AgentOS(
    description="Example app for basic agent with eval capabilities",
    os_id="eval-demo",
    agents=[basic_agent],
)
app = agent_os.get_app()

if __name__ == "__main__":
    # Expose eval endpoints
    agent_os.serve(app="evals_demo:app", reload=True)
```

  </Step>
  <Step title="Run and explore eval runs">

```shell
python cookbook/os/evals_demo.py
```

Explore eval endpoints:

```text
http://localhost:8001/eval/{index}/eval-runs
http://localhost:8001/eval/{index}/eval-runs/123
http://localhost:8001/eval/{index}/eval-runs?agent_id=123
http://localhost:8001/eval/{index}/eval-runs?limit=10&page=0&sort_by=created_at&sort_order=desc
http://localhost:8001/eval/{index}/eval-runs/accuracy
http://localhost:8001/eval/{index}/eval-runs/performance
http://localhost:8001/eval/{index}/eval-runs/reliability
```

  </Step>
</Steps>
