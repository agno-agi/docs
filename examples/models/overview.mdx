---
title: Model Examples
sidebarTitle: Overview
description: 400+ examples across 40+ LLM providers. Same Agent code, any model.
---

Agno's model abstraction lets you switch providers with one line of code. Every example in this section works with the same Agent interface.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.models.anthropic import Claude
from agno.models.google import Gemini

# Same agent, different models
agent = Agent(model=OpenAIResponses(id="gpt-5.2"))
agent = Agent(model=Claude(id="claude-sonnet-4-5"))
agent = Agent(model=Gemini(id="gemini-2.0-flash"))
```

## Supported Providers

<CardGroup cols={3}>
  <Card title="OpenAI" icon="brain" href="/examples/models/openai">
    GPT-4o, GPT-5, o1, o3-mini. 63 examples.
  </Card>
  <Card title="Anthropic" icon="message" href="/examples/models/anthropic">
    Claude Sonnet, Opus, extended thinking. 41 examples.
  </Card>
  <Card title="Google" icon="google" href="/examples/models/google">
    Gemini 1.5, 2.0, multimodal. 58 examples.
  </Card>
  <Card title="Open Source" icon="code-branch" href="/examples/models/open-source">
    Llama, Mistral, DeepSeek, Qwen. 80+ examples.
  </Card>
  <Card title="Enterprise" icon="building" href="/examples/models/enterprise">
    Azure OpenAI, AWS Bedrock, Vertex AI. 75+ examples.
  </Card>
  <Card title="Local Models" icon="server" href="/examples/models/local">
    Ollama, vLLM, LMStudio, llama.cpp. 45+ examples.
  </Card>
</CardGroup>

## All 40+ Providers

| Provider | Import | Models |
|----------|--------|--------|
| OpenAI | `from agno.models.openai import OpenAIResponses` | gpt-4o, gpt-5, o1, o3-mini |
| Anthropic | `from agno.models.anthropic import Claude` | claude-sonnet-4-5, claude-opus-4-5 |
| Google | `from agno.models.google import Gemini` | gemini-2.0-flash, gemini-1.5-pro |
| Groq | `from agno.models.groq import Groq` | llama-3.3-70b, mixtral-8x7b |
| Mistral | `from agno.models.mistral import MistralChat` | mistral-large, mistral-medium |
| Cohere | `from agno.models.cohere import CohereChat` | command-r-plus, command-r |
| xAI | `from agno.models.xai import xAI` | grok-2, grok-beta |
| DeepSeek | `from agno.models.deepseek import DeepSeek` | deepseek-chat, deepseek-reasoner |
| Together | `from agno.models.together import Together` | Llama, Mistral, Qwen hosted |
| Fireworks | `from agno.models.fireworks import Fireworks` | Optimized open models |
| Perplexity | `from agno.models.perplexity import Perplexity` | sonar-pro, sonar |
| Azure OpenAI | `from agno.models.azure import AzureOpenAI` | Enterprise GPT-4 |
| AWS Bedrock | `from agno.models.aws import BedrockChat` | Claude, Llama via AWS |
| Vertex AI | `from agno.models.vertexai import VertexAI` | Gemini via GCP |
| Ollama | `from agno.models.ollama import Ollama` | Local Llama, Mistral |
| vLLM | `from agno.models.vllm import vLLM` | High-performance local |
| LMStudio | `from agno.models.lmstudio import LMStudio` | Desktop local models |
| Cerebras | `from agno.models.cerebras import Cerebras` | Fast inference |
| NVIDIA | `from agno.models.nvidia import NVIDIAChat` | Enterprise NVIDIA |
| IBM | `from agno.models.ibm import IBMChat` | watsonx.ai |
| Hugging Face | `from agno.models.huggingface import HuggingFace` | Any HF model |
| LiteLLM | `from agno.models.litellm import LiteLLM` | Universal proxy |

## Quick Start

```python
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(id="claude-sonnet-4-5"),
    instructions=["Be concise"],
    markdown=True,
)

agent.print_response("What is quantum computing?", stream=True)
```

## Run the Examples

```bash
git clone https://github.com/agno-agi/agno.git
cd agno/cookbook/92_models

# OpenAI
python openai/chat/basic_agent.py

# Anthropic
python anthropic/claude/basic_agent.py

# Google
python google/gemini/basic_agent.py
```

## Next

- [OpenAI Examples](/examples/models/openai) - GPT-4o, o1, o3
- [Anthropic Examples](/examples/models/anthropic) - Claude with extended thinking
- [Google Examples](/examples/models/google) - Gemini multimodal
