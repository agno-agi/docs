---
title: Open Source Models
sidebarTitle: Open Source
description: 88 examples covering Llama, Mistral, DeepSeek, Qwen via Groq, Together, Fireworks.
---

Access open-source models like Llama, Mistral, and DeepSeek through high-performance inference providers. Same Agent code, multiple hosting options.

```python
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    markdown=True,
)

agent.print_response("What are the benefits of open-source AI?", stream=True)
```

## Providers

| Provider | Best For | Models |
|----------|----------|--------|
| Groq | Fastest inference | Llama 3.3, Mixtral, DeepSeek-R1 |
| Together | Wide model selection | Llama, Mistral, Qwen, CodeLlama |
| Fireworks | Optimized performance | Llama, Mistral, custom fine-tunes |
| DeepSeek | Native DeepSeek access | DeepSeek-Chat, DeepSeek-Reasoner |
| Mistral | Native Mistral access | Mistral Large, Medium, Small |
| Cohere | Enterprise features | Command-R+, Command-R |

## Groq (24 examples)

Groq provides the fastest inference for open-source models.

### Basic Chat

```python cookbook/92_models/groq/basic.py
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.3-70b-versatile"), markdown=True)
agent.print_response("Share a 2 sentence horror story")
```

### Reasoning with DeepSeek-R1

```python cookbook/92_models/groq/reasoning_agent.py
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b",
        temperature=0.6,
        max_tokens=1024,
    ),
)

agent.print_response("Is 9.11 bigger or 9.9?", stream=True)
```

### Tool Use

```python cookbook/92_models/groq/tool_use.py
from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("What's the latest news about AI?")
```

### Vision (Llama Vision)

```python cookbook/92_models/groq/image_agent.py
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.2-90b-vision-preview"))
agent.print_response(
    "Describe this image",
    images=["https://example.com/image.jpg"],
)
```

## DeepSeek (10 examples)

Direct access to DeepSeek's models including the DeepSeek-Reasoner.

### Basic Chat

```python cookbook/92_models/deepseek/basic.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek

agent = Agent(model=DeepSeek(id="deepseek-chat"), markdown=True)
agent.print_response("Explain transformer architecture")
```

### Reasoning Agent

```python cookbook/92_models/deepseek/reasoning_agent.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek

agent = Agent(
    model=DeepSeek(id="deepseek-reasoner"),
    reasoning=True,
)

agent.print_response(
    "A bat and ball cost $1.10. The bat costs $1 more than the ball. How much does the ball cost?",
    stream=True,
    show_full_reasoning=True,
)
```

### Tool Use

```python cookbook/92_models/deepseek/tool_use.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=DeepSeek(id="deepseek-chat"),
    tools=[YFinanceTools(stock_price=True)],
)

agent.print_response("What's AAPL's stock price?")
```

## Mistral (17 examples)

Native access to Mistral AI models.

### Basic Chat

```python cookbook/92_models/mistral/basic.py
from agno.agent import Agent
from agno.models.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="mistral-small-latest"),
    markdown=True,
)

agent.print_response("What is quantum computing?")
```

### Tool Use

```python cookbook/92_models/mistral/tool_use.py
from agno.agent import Agent
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(id="mistral-large-latest"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("Search for recent AI breakthroughs")
```

## Together (13 examples)

Access to a wide range of open-source models.

### Basic Chat

```python cookbook/92_models/together/basic.py
from agno.agent import Agent
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"),
    markdown=True,
)

agent.print_response("Explain the CAP theorem")
```

### Tool Use

```python cookbook/92_models/together/tool_use.py
from agno.agent import Agent
from agno.models.together import Together
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"),
    tools=[YFinanceTools(stock_price=True)],
)

agent.print_response("What's TSLA trading at?")
```

## Fireworks (8 examples)

Optimized inference for open-source models.

```python cookbook/92_models/fireworks/basic.py
from agno.agent import Agent
from agno.models.fireworks import Fireworks

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-70b-instruct"),
    markdown=True,
)

agent.print_response("What are microservices?")
```

## Cohere (16 examples)

Enterprise-grade models with retrieval augmentation.

```python cookbook/92_models/cohere/basic.py
from agno.agent import Agent
from agno.models.cohere import CohereChat

agent = Agent(
    model=CohereChat(id="command-r-plus"),
    markdown=True,
)

agent.print_response("Explain RAG architecture")
```

## All 88 Examples

| Provider | Count | Examples |
|----------|-------|----------|
| Groq | 24 | `basic.py`, `tool_use.py`, `reasoning_agent.py`, `image_agent.py`, `knowledge.py` |
| Mistral | 17 | `basic.py`, `tool_use.py`, `structured_output.py`, `pdf_input.py` |
| Cohere | 16 | `basic.py`, `tool_use.py`, `rag_agent.py`, `rerank.py` |
| Together | 13 | `basic.py`, `tool_use.py`, `structured_output.py` |
| DeepSeek | 10 | `basic.py`, `reasoning_agent.py`, `tool_use.py`, `thinking_tool_calls.py` |
| Fireworks | 8 | `basic.py`, `tool_use.py`, `structured_output.py` |

## Run Examples

```bash
git clone https://github.com/agno-agi/agno.git
cd agno/cookbook/92_models

# Groq (fastest)
export GROQ_API_KEY=xxx
python groq/basic.py

# DeepSeek
export DEEPSEEK_API_KEY=xxx
python deepseek/reasoning_agent.py

# Mistral
export MISTRAL_API_KEY=xxx
python mistral/basic.py
```

## Next

- [Enterprise Models](/examples/models/enterprise) - Azure, AWS Bedrock, Vertex AI
- [Local Models](/examples/models/local) - Ollama, vLLM, LMStudio
- [Models Overview](/examples/models/overview) - All 40+ providers
