---
title: Local Models
sidebarTitle: Local
description: 48 examples covering Ollama, vLLM, LMStudio, llama.cpp for private, offline AI.
---

Run models locally for complete privacy and offline operation. No data leaves your machine, no API costs.

```python
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    markdown=True,
)

agent.print_response("Explain the benefits of local AI", stream=True)
```

## Providers

| Provider | Best For | Setup |
|----------|----------|-------|
| Ollama | Easy setup, wide model support | `ollama pull llama3.1` |
| vLLM | High-performance serving | Docker or pip install |
| LMStudio | Desktop GUI | Download app |
| llama.cpp | Minimal dependencies | Build from source |

## Ollama (20 examples)

The easiest way to run local models. One command to install, one to run.

### Basic Chat

```python cookbook/92_models/ollama/basic.py
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)
agent.print_response("Share a 2 sentence horror story")
```

### Reasoning with Local Models

```python cookbook/92_models/ollama/reasoning_agent.py
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="deepseek-r1:8b"),
    reasoning=True,
)

agent.print_response(
    "How many r's are in the word 'strawberry'?",
    show_reasoning=True,
)
```

### Vision with LLaVA

```python cookbook/92_models/ollama/image_agent.py
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llava:13b"))
agent.print_response(
    "What's in this image?",
    images=["photo.jpg"],
)
```

### Tool Use

```python cookbook/92_models/ollama/tool_use.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("Search for recent AI news")
```

### Different Models

```python cookbook/92_models/ollama/demo_qwen.py
from agno.agent import Agent
from agno.models.ollama import Ollama

# Qwen for multilingual
agent = Agent(model=Ollama(id="qwen2.5:7b"))
agent.print_response("Translate 'Hello' to Chinese, Japanese, and Korean")
```

```python cookbook/92_models/ollama/demo_phi4.py
from agno.agent import Agent
from agno.models.ollama import Ollama

# Phi-4 for reasoning
agent = Agent(model=Ollama(id="phi4:14b"))
agent.print_response("Solve: If 3x + 7 = 22, what is x?")
```

## vLLM (12 examples)

High-performance inference server for production deployments.

### Basic Chat

```python cookbook/92_models/vllm/basic.py
from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20),
    markdown=True,
)

agent.print_response("Explain containerization")
```

### Tool Use

```python cookbook/92_models/vllm/tool_use.py
from agno.agent import Agent
from agno.models.vllm import VLLM
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=VLLM(id="meta-llama/Meta-Llama-3.1-8B-Instruct"),
    tools=[YFinanceTools(stock_price=True)],
)

agent.print_response("What's NVDA's stock price?")
```

### Structured Output

```python cookbook/92_models/vllm/structured_output.py
from pydantic import BaseModel
from agno.agent import Agent
from agno.models.vllm import VLLM

class Analysis(BaseModel):
    summary: str
    sentiment: str
    score: float

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct"),
    output_schema=Analysis,
)

response = agent.run("Analyze: 'The product works great!'")
print(response.content)
```

### Code Generation

```python cookbook/92_models/vllm/code_generation.py
from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(
    model=VLLM(id="codellama/CodeLlama-13b-Instruct-hf"),
    markdown=True,
)

agent.print_response("Write a Python function to find prime numbers")
```

## LMStudio (10 examples)

Desktop application for running local models with a GUI.

### Basic Chat

```python cookbook/92_models/lmstudio/basic.py
from agno.agent import Agent
from agno.models.lmstudio import LMStudio

agent = Agent(model=LMStudio(id="qwen2.5-7b-instruct-1m"), markdown=True)
agent.print_response("What is machine learning?")
```

### Tool Use

```python cookbook/92_models/lmstudio/tool_use.py
from agno.agent import Agent
from agno.models.lmstudio import LMStudio
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LMStudio(id="llama-3.1-8b-instruct"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("Search for Python tutorials")
```

## llama.cpp (6 examples)

Direct llama.cpp integration for minimal dependencies.

```python cookbook/92_models/llama_cpp/basic.py
from agno.agent import Agent
from agno.models.llamacpp import LlamaCpp

agent = Agent(
    model=LlamaCpp(
        id="llama-3.1-8b-instruct",
        path="/path/to/model.gguf",
    ),
    markdown=True,
)

agent.print_response("Explain neural networks")
```

## All 48 Examples

| Provider | Count | Examples |
|----------|-------|----------|
| Ollama | 20 | `basic.py`, `reasoning_agent.py`, `image_agent.py`, `tool_use.py`, `demo_*.py` |
| vLLM | 12 | `basic.py`, `tool_use.py`, `structured_output.py`, `code_generation.py` |
| LMStudio | 10 | `basic.py`, `tool_use.py`, `structured_output.py` |
| llama.cpp | 6 | `basic.py`, `tool_use.py` |

## Setup Guides

### Ollama

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull llama3.1:8b

# Run examples
cd agno/cookbook/92_models/ollama
python basic.py
```

### vLLM

```bash
# Install vLLM
pip install vllm

# Start the server
vllm serve Qwen/Qwen2.5-7B-Instruct --port 8000

# Run examples
cd agno/cookbook/92_models/vllm
python basic.py
```

### LMStudio

1. Download LMStudio from [lmstudio.ai](https://lmstudio.ai)
2. Download a model through the GUI
3. Start the local server (default port 1234)
4. Run examples:

```bash
cd agno/cookbook/92_models/lmstudio
python basic.py
```

## Popular Local Models

| Model | Size | Best For |
|-------|------|----------|
| Llama 3.1 8B | 4.7 GB | General chat, fast |
| Llama 3.1 70B | 40 GB | Complex reasoning |
| Qwen 2.5 7B | 4.4 GB | Multilingual, coding |
| DeepSeek-R1 8B | 4.9 GB | Reasoning tasks |
| Phi-4 14B | 8.5 GB | Math, reasoning |
| CodeLlama 13B | 7.4 GB | Code generation |
| LLaVA 13B | 8.0 GB | Vision tasks |

## Next

- [Open Source Models](/examples/models/open-source) - Groq, Together (cloud-hosted open source)
- [Enterprise Models](/examples/models/enterprise) - Azure, AWS, Vertex AI
- [Models Overview](/examples/models/overview) - All 40+ providers
