---
title: Workflow Session Metrics
sidebarTitle: Overview
description: Track and analyze workflow performance across runs
---

## What are Workflow Session Metrics?

Workflow session metrics track the performance of your workflow across multiple runs. Agno automatically collects and aggregates metrics like token usage, execution time, and costs for each workflow session.

Unlike individual run metrics (which track a single execution), session metrics give you the cumulative picture of all runs in a session.

## Metrics Collected

For each workflow session, Agno tracks:

- **Token usage:** Input tokens, output tokens, and total tokens
- **Time:** Duration of each run
- **Costs:** Estimated costs based on model pricing
- **Run count:** Number of workflow executions

These metrics aggregate across all steps in your workflow and across all runs in the session.

## Quick Example

```python
from agno.workflow import Workflow
from agno.db.sqlite import SqliteDb

workflow = Workflow(
    name="Research Pipeline",
    db=SqliteDb(db_file="workflows.db"),
    steps=[...],
)

# Run the workflow a few times
workflow.run(input="Task 1")
workflow.run(input="Task 2")
workflow.run(input="Task 3")

# Get aggregated metrics
metrics = workflow.get_session_metrics()

print(f"Total tokens: {metrics.total_tokens}")
print(f"Input tokens: {metrics.input_tokens}")
print(f"Output tokens: {metrics.output_tokens}")
print(f"Total cost: ${metrics.total_cost}")
```

## How Metrics Aggregate

### Across Steps in a Run

When a workflow runs, metrics from all steps are aggregated:

```python
workflow = Workflow(
    name="Three Step Pipeline",
    db=SqliteDb(db_file="pipeline.db"),
    steps=[
        Step(name="Research", agent=researcher),    # Uses 100 tokens
        Step(name="Analyze", agent=analyzer),       # Uses 150 tokens
        Step(name="Summarize", agent=summarizer),   # Uses 80 tokens
    ],
)

result = workflow.run(input="Process data")

# Run metrics = sum of all step metrics
print(result.metrics.total_tokens)  # 330 tokens
```

### Across Multiple Runs

Session metrics accumulate across all runs:

```python
# First run uses 100 tokens
workflow.run(input="Task 1")
metrics = workflow.get_session_metrics()
print(f"After run 1: {metrics.total_tokens} tokens")  # 100

# Second run uses 150 tokens
workflow.run(input="Task 2")
metrics = workflow.get_session_metrics()
print(f"After run 2: {metrics.total_tokens} tokens")  # 250

# Third run uses 200 tokens
workflow.run(input="Task 3")
metrics = workflow.get_session_metrics()
print(f"After run 3: {metrics.total_tokens} tokens")  # 450
```

## Metrics vs Run Metrics

| Feature | Run Metrics | Session Metrics |
|---------|------------|----------------|
| **Scope** | Single workflow execution | All runs in session |
| **Access** | `workflow_run_output.metrics` | `workflow.get_session_metrics()` |
| **When available** | After run completes | After any run completes |
| **Accumulation** | Per-run only | Cumulative |
| **Use case** | Analyze individual execution | Track overall usage |

## Usage Guides

<CardGroup cols={2}>
  <Card title="Access Metrics" icon="chart-bar" href="/basics/sessions/workflow-sessions/metrics/usage/access-metrics">
    Get and work with metrics data
  </Card>
  <Card title="Tracking Patterns" icon="lightbulb" href="/basics/sessions/workflow-sessions/metrics/usage/tracking-patterns">
    Common patterns for monitoring
  </Card>
</CardGroup>

## Metrics Structure

```python
@dataclass
class Metrics:
    # Token counts
    input_tokens: int | None
    output_tokens: int | None
    total_tokens: int | None
    
    # Costs
    input_cost: float | None
    output_cost: float | None
    total_cost: float | None
    
    # Model info
    model_name: str | None
    model_provider: str | None
```

<Note>
`time_to_first_token` is set to `None` for session metrics since it only applies to individual runs.
</Note>

## Related Topics

<CardGroup cols={2}>
  <Card title="Workflow History" icon="clock-rotate-left" href="/basics/sessions/workflow-sessions/workflow-history/overview">
    Access previous run results
  </Card>
  <Card title="Session State" icon="database" href="/basics/sessions/workflow-sessions/session-state/overview">
    Share data between steps
  </Card>
  <Card title="Overview" icon="book" href="/basics/sessions/workflow-sessions/overview">
    Back to workflow sessions basics
  </Card>
  <Card title="Agent Metrics" icon="chart-line" href="/basics/sessions/metrics/agent">
    Agent session metrics
  </Card>
</CardGroup>

## Developer Resources

- View the [Metrics schema](/reference/run/metrics)
- See the [Workflow API](/reference/workflows/workflow)

