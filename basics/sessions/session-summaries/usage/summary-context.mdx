---
title: Use Summary in Context
description: Include session summaries in conversation context for efficient memory
---

This example demonstrates how to use `add_session_summary_to_context=True` to automatically include session summaries in your conversation context, providing efficient long-term memory without the token cost of full history.

## Why Add Summary to Context?

Instead of including dozens of messages from history, you can include a condensed summary. This gives your agent memory of past conversations while dramatically reducing token usage.

<Tabs>
<Tab title="Agent">

## Code

```python summary_context.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url, session_table="sessions")

# Step 1: Create a summary by having a conversation
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    session_id="john_session",
    enable_session_summaries=True,  # Create summaries
)

agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends."
)
agent.print_response("I'm planning a trip to Colorado next month.")

# Step 2: Use the summary in a new conversation
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    session_id="john_session",  # Same session
    add_session_summary_to_context=True,  # Include summary in context
)

# Agent now has context from the summary, not the full history
agent.print_response("What hiking gear should I bring for my trip?")
# Agent responds with Colorado hiking gear recommendations
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg2-binary
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Export your OpenAI API key">
    <CodeGroup>
    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup> 
  </Step>

  <Step title="Run the code">
    ```bash
    python summary_context.py
    ```
  </Step>
</Steps>

</Tab>

<Tab title="Team">

## Code

```python summary_context.py
from agno.agent import Agent
from agno.team import Team
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(model=OpenAIChat(id="gpt-4o-mini"))

# Step 1: Create a summary by having a conversation
team = Team(
    model=OpenAIChat(id="gpt-4o-mini"),
    members=[agent],
    db=db,
    session_id="john_session",
    enable_session_summaries=True,  # Create summaries
)

team.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends."
)
team.print_response("I'm planning a trip to Colorado next month.")

# Step 2: Use the summary in a new conversation
team = Team(
    model=OpenAIChat(id="gpt-4o-mini"),
    members=[agent],
    db=db,
    session_id="john_session",  # Same session
    add_session_summary_to_context=True,  # Include summary in context
)

# Team now has context from the summary, not the full history
team.print_response("What hiking gear should I bring for my trip?")
# Team responds with Colorado hiking gear recommendations
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg2-binary
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Export your OpenAI API key">
    <CodeGroup>
    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup> 
  </Step>

  <Step title="Run the code">
    ```bash
    python summary_context.py
    ```
  </Step>
</Steps>

</Tab>
</Tabs>

## How It Works

When `add_session_summary_to_context=True`:

1. **Summary Loaded**: The session summary is retrieved from the database
2. **Added to Context**: Summary is included in the messages sent to the model
3. **Token Efficient**: Only the summary is sent, not the full conversation history

### Example Flow

**Without summary (using full history):**
```
Context sent to model:
  - Message 1: "My name is John Doe..."
  - Message 2: "I'm planning a trip..."
  - Message 3: [Previous responses]
  - Current: "What hiking gear...?"
→ High token cost
```

**With summary (efficient):**
```
Context sent to model:
  - Summary: "User John Doe enjoys hiking, planning Colorado trip"
  - Current: "What hiking gear...?"
→ Low token cost, same context
```

## Combining with History

You can use both summaries and recent history for optimal results:

```python
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    enable_session_summaries=True,       # Create summaries
    add_session_summary_to_context=True, # Include summary
    add_history_to_context=True,          # Also include recent history
    num_history_runs=2,                   # Just last 2 runs
)
```

This gives you:
- ✅ Long-term context from summary
- ✅ Detailed recent context from last 2 runs
- ✅ Balanced token usage

## Control When Summaries Are Used

You can control whether to create new summaries or just use existing ones:

```python
# Create and update summaries
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    enable_session_summaries=True,        # Creates/updates summaries
    add_session_summary_to_context=True,  # Also uses them
)

# Only use existing summaries (don't create new ones)
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    enable_session_summaries=False,       # Don't create new summaries
    add_session_summary_to_context=True,  # But use existing ones
)
```

## Use Cases

### Long-Running Conversations
Perfect for customer support where conversations span days or weeks:

```python
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    session_id=f"support_{user_id}",
    add_session_summary_to_context=True,  # Remember context efficiently
)
```

### Multi-Session Context
Carry context across multiple related sessions:

```python
# Session 1: Initial consultation
agent.run("I need help with my account", session_id="user_123_session_1")

# Session 2 (days later): Follow-up
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    session_id="user_123_session_2",
    # Could load summary from session_1 here if needed
)
```

## Key Points

- **Token Efficient**: Summaries use far fewer tokens than full history
- **Automatic Loading**: Summary is automatically retrieved and added to context
- **Flexible**: Combine with recent history for best of both worlds
- **Stateless Agent**: Can create new agent instances and still have context
- **Production Ready**: Ideal for long-running production conversations

## Best Practices

### ✅ Do This

```python
# For long conversations - use summaries
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    enable_session_summaries=True,
    add_session_summary_to_context=True,
    num_history_runs=2,  # Recent detail + summary context
)
```

### ⚠️ Consider This

```python
# For short conversations - history alone is fine
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    db=db,
    add_history_to_context=True,
    num_history_runs=5,  # No summary needed for short chats
)
```

## Next Steps

- Learn about [enabling session summaries](/basics/sessions/session-summaries/usage/enable-summaries)
- Explore [storage control](/basics/sessions/storage-control/overview) to optimize what gets saved
- Review [history management](/basics/sessions/history-management/overview) for controlling conversation history

