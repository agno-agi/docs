---
title: Streaming Agent Responses
sidebarTitle: Streaming Agent
description: Learn how to stream your agent's responses
mode: wide
---

In this example, we will see how to stream the responses from an agent.

This is useful when you want to process or show the response in real-time, as it's generated.

<Steps>

  <Step title="Create a Python file">
    ```python streaming.py
    from agno.agent import Agent
    from agno.models.openai import OpenAIResponses
    from agno.run.agent import RunEvent

    agent = Agent(
        model=OpenAIResponses(id="gpt-5.2"),
        instructions="You are a helpful assistant. All your responses must be brief and concise.",
    )

    # Run the agent with stream=True
    stream = agent.run("Trending products", stream=True)

    # Consume the streaming response
    for chunk in stream:
        if chunk.event == RunEvent.run_content:
            print(chunk.content)

    ```
  </Step>

  <Snippet file="create-venv-step.mdx" />

  <Step title="Install dependencies">
    ```bash
    uv pip install -U agno openai
    ```
  </Step>

  <Step title="Export your OpenAI API key">

    <CodeGroup>

    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python streaming.py
    ```

    ```bash Windows
    python streaming.py
    ```
    </CodeGroup>
  </Step>

</Steps>
