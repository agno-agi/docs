---
title: Rate limit errors
description: Learn how to handle rate limit errors.
---

![Chat with pdf](/images/tpm_issues.png)

Propietary models, like OpenAI models, have rate limits. The most common ones are tokens-per-minute (TPM) limits and and requests per minute (RPM) limits.

To help handle both, Agno provides the option to set `exponential_backoff` and `delay_between_retries`:

For example:
```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are an enthusiastic news reporter with a flair for storytelling!",
    markdown=True,
    # Setting exponential_backoff to True, the Agent will retry failed requests with an increasing delay.
    exponential_backoff=True,
    # Setting delay_between_retries you can adjust the delay between retries.
    delay_between_retries=2
)
agent.print_response("Tell me about a breaking news story from New York.", stream=True)
```

See our [models documentation](/docs/documentation/models) for specific information about rate limiting.

In the case of OpenAI, they have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.
