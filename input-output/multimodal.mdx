---
title: Multimodal I/O
description: Pass images, audio, video, and files to agents.
---

Agents can process images, audio, video, and files as input, 
and generate images and audio as output.

This section introduces Multimodal I/O. Check out the [full guide](/multimodal/overview) for more details.

## Multimodal Input

### Media Classes

| Class | Parameters |
|-------|------------|
| `Image` | `url`, `filepath`, `content` (bytes) |
| `Audio` | `url`, `filepath`, `content` (bytes), `format` |
| `Video` | `url`, `filepath`, `content` (bytes) |
| `File` | `url`, `filepath`, `content` (bytes) |

### Image Input

Pass images via URL, file path, or base64 content:
```python
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="gpt-5.2"))

# From URL
agent.run(
    "What's in this image?",
    images=[Image(url="https://example.com/photo.jpg")]
)

# From file
agent.run(
    "Describe this image",
    images=[Image(filepath="./photo.jpg")]
)

# Multiple images
agent.run(
    "Compare these two images",
    images=[
        Image(url="https://example.com/photo1.jpg"),
        Image(url="https://example.com/photo2.jpg")
    ]
)
```

### Audio Input

Pass audio files for transcription or analysis:
```python
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIResponses

agent = Agent(
    model=OpenAIResponses(id="gpt-4o-audio-preview", modalities=["text"])
)

# From file
agent.run(
    "What is being said in this audio?",
    audio=[Audio(filepath="./recording.wav")]
)

# From bytes
with open("recording.wav", "rb") as f:
    audio_bytes = f.read()

agent.run(
    "Transcribe this audio",
    audio=[Audio(content=audio_bytes, format="wav")]
)
```

### Video Input

Pass video files for analysis:
```python
from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-exp"))

agent.run(
    "Describe what happens in this video",
    videos=[Video(filepath="./clip.mp4")]
)
```

<Note>
Video input is currently supported by Gemini models only.
</Note>

### File Input

Pass documents like PDFs:
```python
from agno.agent import Agent
from agno.media import File
from agno.models.anthropic import Claude

agent = Agent(model=Claude(id="claude-sonnet-4-5"))

# From URL
agent.run(
    "Summarize this document",
    files=[File(url="https://example.com/report.pdf")]
)

# From file path
agent.run(
    "What are the key points in this PDF?",
    files=[File(filepath="./report.pdf")]
)
```

## Multimodal Output

### Image Generation

Generate images using tools like DALL-E:
```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.dalle import DalleTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    tools=[DalleTools()],
)

agent.run("Generate an image of a sunset over mountains")

# Get generated images
images = agent.get_images()
for image in images:
    print(image.url)
```

### Audio Generation

Generate audio responses:
```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIResponses(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
)

response = agent.run("Tell me a short story")

# Save audio to file
if response.response_audio:
    write_audio_to_file(
        audio=response.response_audio.content,
        filename="story.wav"
    )
```

## Combined Multimodal I/O 

Process audio input and generate audio output:
```python
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIResponses
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIResponses(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
)

response = agent.run(
    "Respond to this message",
    audio=[Audio(filepath="./question.wav")]
)

if response.response_audio:
    write_audio_to_file(
        audio=response.response_audio.content,
        filename="response.wav"
    )
```

## Learn More

For more details, see the [Multimodal documentation](/multimodal/overview):