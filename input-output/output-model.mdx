---
title: Output Model
sidebarTitle: Output Model
description: Use a secondary model to format the final response.
---

Agno supports a modular model pipeline for response refinement; implement only the stages necessary for your workflow.

## Model Pipeline

1. Primary model generates response (Optionally feed this as intermediate response to the secondary model)
2. Secondary model processes, formats and returns the final response
3. Final response passes to the optional tertiary model that acts as a custom formatter or validator

Use the following parameters to build pipeline stages:

- `model`: Mandatory, specifies the primary model to generate a response
- `output_schema`: The schema to validate the response against
- `output_model`: The secondary model to further process and format the primary model response
- `output_model_prompt`: Additional custom formatting or output refining instructions for the secondary/final model
- `parser_model`: The tertiary model used to format the response for better outcomes
- `parser_model_prompt`: Additional instructions to control the `parser_model` output during the extraction step

## Model Selection

Design your agent based on three dimensions: Reasoning (Logic), Presentation (Style), and Structure (Schema)

* `model`: Select the 'doer' or 'pipeline brain' based on reasoning capabity *(for example, GPT-4o for complex tasks, Claude-3 for simple ones)*.
* `output_model`: Select the 'formatter' or 'pipeline stylist' based on formatting capability *(for example, Claude Opus 4.5 for prose, GPT-5-mini for cost optimization)*.
* `parser_model`: Select the 'validator' or 'pipeline validator' as a fallback if the primary model supports native structured output or when you need structured data from weaker models or messy text outputs.*(For example, with OpenAI/Anthropic, use `parser_model` with a smart model (like GPT-4o) to "fix" or "extract" desired output)*.

<Note>
`parser_model` is used when the primary model cannot reliably produce structured output (JSON/Pydantic) on its own.

For example, consider the scenarios:

**Weak Primary Model**:

When primary models (for example, local LLMs via Ollama) fail to adhere to strict JSON schemas, leverage a more capable parser_model (such as GPT-4o) to post-process and validate the output.

**No Native Support**:

If the primary model provider does not support native "Structured Outputs" (such as tool calling or JSON mode), then 
use `parser_model` to extract the desired data.
</Note>

## Custom Output Style 

### `output_model_prompt`

Use `output_model_prompt` optionally whenever you use an `output_model` to set the style, 
tone, and format for the Formatter (secondary model). It replaces the default System Prompt for the `output_model`.

```python
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

# Executive summary style
agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    output_model=Claude(id="claude-sonnet-4-5"),
    output_model_prompt="Format as a concise executive summary. No fluff, just insights.",
    tools=[HackerNewsTools()],
)

# Technical documentation style
agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),
    output_model=Claude(id="claude-sonnet-4-5"),
    output_model_prompt="Format as technical documentation with code examples where relevant.",
    tools=[HackerNewsTools()],
)
```
<Note>
**Default Behavior (if you don't set `output_model_prompt`):**

Without `output_model_prompt`, the 
`output_model` will just summarize/rewrite the content in its default voice, which may not be what you want.

**When to use it:** 

Use it to set the tone (Write a professional, executive summary), format (Format as technical documentation with code examples where relevant), or audience (Explain to a layman or ELI5) for the response.
</Note>

### `parser_model_prompt`

The `parser_model_prompt` is optional. In most cases,the default system prompt works well for schema extraction tasks.
Use it optionally whenever you use a `parser_model` to set the style, tone, and format for the Validator (tertiary model).  

```python
from typing import List
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.models.ollama import Ollama
from pydantic import BaseModel, Field
class MovieScript(BaseModel):
    setting: str = Field(..., description="Provide a nice setting for a blockbuster movie.")
    ending: str = Field(..., description="Ending of the movie. If not available, provide the best ending you can think of.")
    genre: str = Field(..., description="Genre of the movie. If not available, select the best genre you can think of.")
    name: str = Field(..., description="Name of the movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(..., description="3 sentence storyline for the movie. Make it exciting!")
# Agent with a parser model + custom parser prompt
agent = Agent(
    model=Ollama(id="llama3.1"),
    description="You are a movie script writer.",
    output_schema=MovieScript,
    parser_model=OpenAIChat(id="gpt-4o"),
    parser_model_prompt="Extract the movie details from the input. Ensure the JSON is valid and matches the MovieScript schema exactly."
)
agent.print_response("New york")
```

<Note>
**Default Behavior (if you don't set `parser_model_prompt`):** 

The specified `parser_model` 
prompt defaults to: "You are tasked with creating a structured output from the provided user 
message." (or similar).

**When to use it:** 

You only need to set this if the default extraction fails or 
if you need to provide specific rules for how to extract the data (for example, "Extract 
dates in YYYY-MM-DD format" or "Extract only the first 3 items").
</Note>

## Use Case

| Use Case | Configuration |
|----------|----------------|
| Need better prose quality | `output_model` = Claude Opus 4.5 |
| Need to reduce costs | `output_model` = GPT-5-mini |
| Primary model lacks structured output or lacks desired formatting | `parser_model` = GPT-4o, `output_schema` = your desired schema, `output_model` = Claude Opus 4.5 |
| Need custom formatting style | `output_model` = Claude Opus 4.5, `output_model_prompt` = your desired formatting instructions |
| Simple structured data extraction | `output_schema` = your desired schema |
| Standard Agent | `model` = OpenAIResponses(id="gpt-5.2") |
| Strict JSON   | `model` = OpenAIResponses(id="gpt-5.2") and `output_schema` = your desired schema |
| Strict JSON (Weak Model) | `model` = OpenAIResponses(id="gpt-5.2") and `parser_model` = GPT-4o and `output_schema` = your desired schema |
| Reasoning + Great Prose | `model` = OpenAIResponses(id="gpt-5.2") and `output_model` = Claude Opus 4.5 |
| Cost Efficient | `model` = OpenAIResponses(id="gpt-5.2") and `output_model` = GPT-5-mini |


## Examples 

| Use Case | Example |
|----------|---------|
| Better writing | Research with GPT-5.2, write with Claude Opus 4.5 |
| Cost optimization | Reason with DeepSeek, format with GPT-5-mini |
| Structured output | Use a model without native support, format with one that has it |

### Better Writing

GPT-5.2 excels at research and tool use, but Claude Opus 4.5 produces better prose. Combine them:
```python
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),       # Research and tool calls
    output_model=Claude(id="claude-opus-4-5"), # Creative writing
    output_model_prompt="Write an engaging, well-structured article based on these findings.",
    tools=[HackerNewsTools()],
)

agent.print_response("Write an article about the latest AI breakthroughs", stream=True)
```

The primary model gathers information from HackerNews. Claude Opus 4.5 transforms those findings into polished prose.

### Cost Optimization

Use a capable but expensive model for complex reasoning, a cheaper model for formatting:
```python
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),       # Expensive: complex analysis + tools
    output_model=OpenAIResponses(id="gpt-5-mini"),  # Cheap: just formatting
    output_model_prompt="Summarize the analysis in 3 bullet points.",
    tools=[YFinanceTools()],
)

agent.print_response("Deep analysis of NVDA financials", stream=True)
```

Or use a cheaper reasoning model with a better formatting model:
```python
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=DeepSeek(id="deepseek-chat"),        # Cheap: reasoning + tools
    output_model=OpenAIResponses(id="gpt-5.2"), # Better formatting
    tools=[YFinanceTools()],
)

agent.print_response("Analyze AAPL stock performance", stream=True)
```

### Structured Output Support

Some models lack native structured output. Use an output model that supports it:
```python
from pydantic import BaseModel, Field
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.hackernews import HackerNewsTools

class ArticleSummary(BaseModel):
    title: str
    key_points: list[str] = Field(description="3-5 main takeaways")
    sentiment: str = Field(description="positive, negative, or neutral")

agent = Agent(
    model=OpenAIResponses(id="gpt-5.2"),            # Primary reasoning
    output_model=OpenAIResponses(id="gpt-5.2"),    # Structured output
    output_schema=ArticleSummary,
    tools=[HackerNewsTools()],
)

response = agent.run("Summarize the top AI story on HackerNews")
summary: ArticleSummary = response.content
print(summary.key_points)
```

## Related

- [Structured Output](/input-output/structured-output/agent): Get validated Pydantic objects
- [Structured Input](/input-output/structured-input/agent): Pass validated input to agents