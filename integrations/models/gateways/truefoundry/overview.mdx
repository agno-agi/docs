---
title: TrueFoundry AI Gateway
sidebarTitle: Overview
description: Learn how to use models through TrueFoundry AI Gateway in Agno.
---

[TrueFoundry](https://truefoundry.com/ai-gateway) is an enterprise-grade AI Gateway and control plane that lets you deploy, govern, and monitor any LLM or Gen-AI workload behind a single OpenAI-compatible API bringing rate-limiting, cost controls, observability, and on-prem support to production AI applications.

With TrueFoundry AI Gateway, you can:

- **Cost Tracking**: Monitor and track costs across all your agents and teams
- **Security**: Centralized API key management for enhanced security
- **Access Controls**: Fine-grained access controls for different teams and agents
- **Rate Limiting**: Prevent API quota exhaustion with intelligent rate limiting
- **Fallback Support**: Automatic failover to alternative providers when needed
- **Analytics**: Detailed analytics and monitoring for all LLM calls
- **Multi-Provider Support**: Seamlessly switch between different model providers (OpenAI, Anthropic, Gemini, etc.)

## Prerequisites

Before integrating Agno with TrueFoundry AI Gateway, ensure you have:

1. **TrueFoundry Account**: Create a [TrueFoundry account](https://truefoundry.com/register) and follow the [Gateway Quick Start Guide](https://truefoundry.com/docs/ai-gateway/quick-start)
2. **Agno Installation**: Install Agno using pip:

```shell
pip install agno
```

## Authentication

You can find the API key and base url in the unified code snippet from the playground:

<Frame caption="Get your API key and Gateway URL from the TrueFoundry console">
  <img src="/images/new-code-snippet.avif" alt="TrueFoundry Code Snippet" />
</Frame>

Set up your environment variables:

<CodeGroup>

```bash Mac/Linux
export TRUEFOUNDRY_API_KEY=your-truefoundry-api-key
export TRUEFOUNDRY_BASE_URL=your-truefoundry-gateway-url
```

```bash Windows
setx TRUEFOUNDRY_API_KEY your-truefoundry-api-key
setx TRUEFOUNDRY_BASE_URL your-truefoundry-gateway-url
```

</CodeGroup>

## Example

Since TrueFoundry AI Gateway is OpenAI-compatible, use `OpenAIChat` with your TrueFoundry credentials:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(
        id="openai-main/gpt-4o",  # Use your TrueFoundry model name
        api_key="your-truefoundry-api-key",
        base_url="your-truefoundry-gateway-url"
    ),
    description="AI assistant powered by TrueFoundry Gateway",
    instructions=[
        "You are a helpful AI assistant",
        "Provide accurate and concise responses"
    ],
    markdown=True
)

# Print the response
agent.print_response("What is the capital of France?")
```

</CodeGroup>

## Using Environment Variables

For production use, configure your agents using environment variables:

```python
import os
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(
        id="openai-main/gpt-4o",
        api_key=os.getenv("TRUEFOUNDRY_API_KEY"),
        base_url=os.getenv("TRUEFOUNDRY_BASE_URL")
    ),
    name="Assistant",
    description="General purpose AI assistant"
)

response = agent.run("What is the capital of Brazil?")
print(response.content)
```

## Multi-Agent Team

Create a team of specialized agents for complex tasks:

```python
import os
from agno.agent import Agent
from agno.team import Team
from agno.models.openai import OpenAIChat

TRUEFOUNDRY_API_KEY = os.getenv("TRUEFOUNDRY_API_KEY")
TRUEFOUNDRY_BASE_URL = os.getenv("TRUEFOUNDRY_BASE_URL")

# Research Agent
researcher = Agent(
    model=OpenAIChat(
        id="openai-main/gpt-4o",
        api_key=TRUEFOUNDRY_API_KEY,
        base_url=TRUEFOUNDRY_BASE_URL
    ),
    name="Researcher",
    description="Conducts thorough research on topics",
    instructions=[
        "Research the given topic thoroughly",
        "Provide factual and well-sourced information"
    ]
)

# Writer Agent
writer = Agent(
    model=OpenAIChat(
        id="openai-main/gpt-4o",
        api_key=TRUEFOUNDRY_API_KEY,
        base_url=TRUEFOUNDRY_BASE_URL
    ),
    name="Writer",
    description="Creates well-structured content",
    instructions=[
        "Write clear and engaging content",
        "Structure information logically"
    ]
)

# Create team
research_team = Team(
    agents=[researcher, writer],
    instructions=[
        "Researcher should investigate the topic first",
        "Writer should create content based on research findings"
    ]
)

# Execute team task
result = research_team.run("Research and write about sustainable energy solutions")
```

## Using Different Model Providers

TrueFoundry AI Gateway supports multiple model providers. Simply change the model ID to use different providers:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
import os

# Using Anthropic Claude through TrueFoundry
agent = Agent(
    model=OpenAIChat(
        id="anthropic/claude-3-5-sonnet",  # Anthropic model via TrueFoundry
        api_key=os.getenv("TRUEFOUNDRY_API_KEY"),
        base_url=os.getenv("TRUEFOUNDRY_BASE_URL")
    ),
    markdown=True
)

agent.print_response("Explain quantum computing in simple terms")
```

## Cost Monitoring

TrueFoundry AI Gateway provides built-in cost tracking and analytics for all your LLM calls:

<Frame caption="Monitor costs across all your agents and teams">
  <img src="/images/monitoring cost.avif" alt="TrueFoundry Cost Monitoring" />
</Frame>

## Benefits of Using TrueFoundry with Agno

| Feature | Description |
| ------- | ----------- |
| **Unified API** | Single OpenAI-compatible API for all model providers |
| **Cost Tracking** | Monitor and optimize costs across all agents |
| **Rate Limiting** | Prevent API quota exhaustion |
| **Access Controls** | Fine-grained permissions for teams |
| **Fallback Support** | Automatic failover to backup providers |
| **Analytics** | Detailed monitoring and debugging |
| **On-Prem Support** | Deploy in your own infrastructure |

## Params

Since TrueFoundry uses the OpenAI-compatible API, you can use all parameters supported by [OpenAI](/reference/models/openai):

| Parameter  | Type            | Default | Description                                      |
| ---------- | --------------- | ------- | ------------------------------------------------ |
| `id`       | `str`           | -       | The TrueFoundry model name (e.g., `openai-main/gpt-4o`) |
| `api_key`  | `Optional[str]` | `None`  | Your TrueFoundry API key                         |
| `base_url` | `Optional[str]` | `None`  | Your TrueFoundry Gateway URL                     |

## Resources

- [TrueFoundry AI Gateway Documentation](https://truefoundry.com/docs/ai-gateway)
- [TrueFoundry Quick Start Guide](https://truefoundry.com/docs/ai-gateway/quick-start)

